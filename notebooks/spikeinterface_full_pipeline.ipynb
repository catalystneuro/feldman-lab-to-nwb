{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpikeInterface pipeline for Tank Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "import spikeextractors as se\n",
    "import spiketoolkit as st\n",
    "import spikesorters as ss\n",
    "import spikecomparison as sc\n",
    "import spikewidgets as sw\n",
    "from nwb_conversion_tools.conversion_tools import save_si_object\n",
    "\n",
    "from tank_lab_to_nwb import TowersProcessedNWBConverter\n",
    "from tank_lab_to_nwb.convert_towers_task.towersprocessednwbconverter import quick_write\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a) Load AP recordings, LF recordings and TTL signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_path = Path(\"/Users/abuccino/Documents/Data/catalyst/brody/A256_bank1_2020_09_30_g0\")\n",
    "#base_data_path = Path(\"D:/Neuropixels/Neuropixels/A256_bank1_2020_09_30/A256_bank1_2020_09_30_g0\")\n",
    "base_data_path = Path(\"20210115_NPX_and_behavior/2021_01_15_E105/towersTask_g0\")\n",
    "ap_bin_path = base_data_path / \"towersTask_g0_imec0\" / \"towersTask_g0_t0.imec0.ap.bin\"\n",
    "lf_bin_path = base_data_path / \"towersTask_g0_imec0\" / \"towersTask_g0_t0.imec0.lf.bin\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make spikeinterface folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_folder = Path(\"20210115_NPX_and_behavior/2021_01_15_E105\")\n",
    "spikeinterface_folder = recording_folder / 'spikeinterface'\n",
    "spikeinterface_folder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) stub recording for fast testing; set to False for running processing pipeline on entire data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stub_test = False\n",
    "nsec_stub = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_ap = se.SpikeGLXRecordingExtractor(ap_bin_path)\n",
    "recording_lf = se.SpikeGLXRecordingExtractor(lf_bin_path)\n",
    "\n",
    "if stub_test:\n",
    "    recording_ap = se.SubRecordingExtractor(recording_ap, end_frame=int(nsec_stub*recording_ap.get_sampling_frequency()))\n",
    "    recording_lf = se.SubRecordingExtractor(recording_lf, end_frame=int(nsec_stub*recording_lf.get_sampling_frequency()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Sampling frequency AP: {recording_ap.get_sampling_frequency()}\")\n",
    "print(f\"Sampling frequency LF: {recording_lf.get_sampling_frequency()}\")      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load TTL signals\n",
    "\n",
    "### (Option 1): Use TTLs from the ap.bin file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttl, states = recording_ap.get_ttl_events()\n",
    "rising_times = ttl[states==1]\n",
    "print(f\"Number of TTL events in ap file: {len(rising_times)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(rising_times) > 0:\n",
    "    start_time = recording_ap.frame_to_time(rising_times[0])\n",
    "    start_frame_ap = int(recording_ap.time_to_frame(start_time))\n",
    "    start_frame_lf = int(recording_lf.time_to_frame(start_time))\n",
    "    print(f\"Start frame AP: {start_frame_ap}\")\n",
    "    print(f\"Start frame LF: {start_frame_lf}\")    \n",
    "else:\n",
    "    print(\"No TTL events found in ap file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Option 2): Use TTLs from the nidq.bin file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nidq_file = base_data_path / \"towersTask_g0_t0.nidq.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_nidq = se.SpikeGLXRecordingExtractor(nidq_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttl_nidq, states_nidq = recording_nidq.get_ttl_events()\n",
    "rising_times_nidq = ttl_nidq[states_nidq==1]\n",
    "print(f\"Number of TTL events in nidq file: {len(rising_times_nidq)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(rising_times_nidq) > 0:\n",
    "    start_time = recording_nidq.frame_to_time(rising_times_nidq[0])\n",
    "    start_frame_ap = int(recording_ap.time_to_frame(start_time))\n",
    "    start_frame_lf = int(recording_lf.time_to_frame(start_time))\n",
    "    print(f\"Start frame AP: {start_frame_ap}\")\n",
    "    print(f\"Start frame LF: {start_frame_lf}\")    \n",
    "else:\n",
    "    print(\"No TTL events found in nidq file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synchronize recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_ap_sync = se.SubRecordingExtractor(recording_ap, start_frame=start_frame_ap)\n",
    "recording_lf_sync = se.SubRecordingExtractor(recording_lf, start_frame=start_frame_lf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ts_ap = sw.plot_timeseries(recording_ap, channel_ids=recording_ap.get_channel_ids()[::4], trange=[100, 105])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ts_lf = sw.plot_timeseries(recording_lf, channel_ids=recording_lf.get_channel_ids()[::4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_cmr = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if apply_cmr:\n",
    "    recording_processed = st.preprocessing.common_reference(recording_ap_sync)\n",
    "else:\n",
    "    recording_processed = recording_ap_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames = recording_processed.get_num_frames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates, amps = st.postprocessing.compute_channel_spiking_activity(recording_processed, n_jobs=16, chunk_mb=4000,\n",
    "                                                                 start_frame=10*30000, end_frame=20*30000, \n",
    "                                                                 detect_threshold=8, recompute_info=True, \n",
    "                                                                 verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2)\n",
    "sw.plot_activity_map(recording_processed, activity=\"rate\", colorbar=True, ax=axs[0])\n",
    "sw.plot_activity_map(recording_processed, activity=\"amplitude\", colorbar=True, ax=axs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Run spike sorters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorter_list = [\n",
    "    'tridesclous',\n",
    "    #'spykingcircus',\n",
    "    'herdingspikes',\n",
    "    #'kilosort2',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inspect sorter-specific parameters and defaults\n",
    "for sorter in sorter_list:\n",
    "    print(f\"{sorter} params description:\")\n",
    "    pprint(ss.get_params_description(sorter))\n",
    "    print(\"Default params:\")\n",
    "    pprint(ss.get_default_params(sorter))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user-specific parameters\n",
    "sorter_params = dict(\n",
    "    #kilosort2=dict(car=False, n_jobs_bin=12, chunk_mb=4000),\n",
    "    #ironclust=dict(filter=True),\n",
    "    tridesclous=dict(n_jobs_bin=12, chunk_mb=4000),\n",
    "    spykingcircus=dict(filter=True, num_workers=16),\n",
    "    herdingspikes=dict(filter=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_outputs = ss.run_sorters(\n",
    "    sorter_list=sorter_list, \n",
    "    recording_dict_or_list=dict(rec0=recording_processed),\n",
    "    working_folder=spikeinterface_folder / \"working1\",\n",
    "    mode=\"keep\", # change to \"keep\" to avoid repeating the spike sorting\n",
    "    sorter_params=sorter_params,\n",
    "    verbose=True,\n",
    "    run_sorter_kwargs=dict(raise_error=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result_name, sorting in sorting_outputs.items():\n",
    "    rec_name, sorter = result_name\n",
    "    print(f\"{sorter} found {len(sorting.get_unit_ids())} units\")\n",
    "    \n",
    "    # tridesclous sometimes has empty clusters\n",
    "    active_units = []\n",
    "    for u in sorting.get_unit_ids():\n",
    "        if len(sorting.get_unit_spike_train(u)) > 0:\n",
    "            active_units.append(u)\n",
    "    \n",
    "    if len(active_units) < len(sorting.get_unit_ids()):\n",
    "        sorting_outputs[result_name] = se.SubSortingExtractor(sorting, unit_ids=active_units)\n",
    "        print(f\"{sorter} found {len(active_units)} units after removing empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sorting_tdc = sorting_outputs[('rec0', 'tridesclous')]\n",
    "sw.plot_unit_templates(recording_processed, sorting_tdc, unit_ids=[11, 21],\n",
    "                       radius=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### (Optional) save individual sorting outputs for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "save_si_object(\"ironclust\", sorting_outputs[('rec0', 'ironclust')], spikeinterface_folder,\n",
    "               cache_raw=False, include_properties=True, include_features=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Post-processing: extract waveforms, templates, quality metrics, extracellular features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Set postprocessing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-processing params\n",
    "postprocessing_params = st.postprocessing.get_postprocessing_params()\n",
    "pprint(postprocessing_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# (optional) change parameters\n",
    "postprocessing_params['max_spikes_per_unit'] = 1000  # with None, all waveforms are extracted\n",
    "postprocessing_params['n_jobs'] = 16  # n jobs\n",
    "postprocessing_params['chunk_mb'] = 4000  # max RAM usage in Mb\n",
    "postprocessing_params['verbose'] = True  # max RAM usage in Mb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Set quality metric list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quality metrics\n",
    "qc_list = st.validation.get_quality_metrics_list()\n",
    "print(f\"Available quality metrics: {qc_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# (optional) define subset of qc\n",
    "qc_list = ['snr', 'isi_violation', 'firing_rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Set extracellular features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracellular features\n",
    "ec_list = st.postprocessing.get_template_features_list()\n",
    "print(f\"Available EC features: {ec_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# (optional) define subset of ec\n",
    "ec_list = ['peak_to_valley', 'halfwidth']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Postprocess all sorting outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for result_name, sorting in sorting_outputs.items():\n",
    "    rec_name, sorter = result_name\n",
    "    print(f\"Postprocessing recording {rec_name} sorted with {sorter}\")\n",
    "    tmp_folder = spikeinterface_folder / 'tmp' / sorter\n",
    "    tmp_folder.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # set local tmp folder\n",
    "    sorting.set_tmp_folder(tmp_folder)\n",
    "    \n",
    "    # compute waveforms\n",
    "    waveforms = st.postprocessing.get_unit_waveforms(recording_processed, sorting, **postprocessing_params)\n",
    "    \n",
    "    # compute templates\n",
    "    templates = st.postprocessing.get_unit_templates(recording_processed, sorting, **postprocessing_params)\n",
    "    \n",
    "    # comput EC features\n",
    "    ec = st.postprocessing.compute_unit_template_features(recording_processed, sorting,\n",
    "                                                          feature_names=ec_list, as_dataframe=True)\n",
    "    # compute QCs\n",
    "    qc = st.validation.compute_quality_metrics(sorting, recording=recording_processed, \n",
    "                                               metric_names=qc_list, as_dataframe=True)\n",
    "    \n",
    "    # export to phy\n",
    "    if sorter == \"kilosort2\":\n",
    "        phy_folder = spikeinterface_folder / 'phy' / sorter\n",
    "        phy_folder.mkdir(parents=True, exist_ok=True)\n",
    "        st.postprocessing.export_to_phy(recording_processed, sorting, phy_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Run phy and load curated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!phy template-gui spikeinterface/phy/kilosort2/params.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_manual_curated = se.PhySortingExtractor(phy_folder, exclude_cluster_groups=['noise'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Kilosort2 found {len(sorting_manual_curated.get_unit_ids())} units after manual curation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 5) Ensemble spike sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if len(sorting_outputs) > 1:\n",
    "    # retrieve sortings and sorter names\n",
    "    sorting_list = []\n",
    "    sorter_names_comp = []\n",
    "    for result_name, sorting in sorting_outputs.items():\n",
    "        rec_name, sorter = result_name\n",
    "        sorting_list.append(sorting)\n",
    "        sorter_names_comp.append(sorter)\n",
    "        \n",
    "    # run multisorting comparison\n",
    "    mcmp = sc.compare_multiple_sorters(sorting_list=sorting_list, name_list=sorter_names_comp)\n",
    "    \n",
    "    # plot agreement results\n",
    "    w_agr = sw.plot_multicomp_agreement(mcmp)\n",
    "    \n",
    "    # extract ensamble sorting\n",
    "    sorting_ensemble = mcmp.get_agreement_sorting(minimum_agreement_count=2)\n",
    "    \n",
    "    print(f\"Ensamble sorting among {sorter_list} found: {len(sorting_ensemble.get_unit_ids())} units\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.plot_rasters(sorting_ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) save ensemble output for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_si_object(\"sorting_ensemble\", sorting_ensemble, spikeinterface_folder,\n",
    "               cache_raw=False, include_properties=True, include_features=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 6) Automatic curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define curators and thresholds\n",
    "isi_violation_threshold = 0.5\n",
    "snr_threshold = 5\n",
    "firing_rate_threshold = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sorting_auto_curated = []\n",
    "sorter_names_curation = []\n",
    "for result_name, sorting in sorting_outputs.items():\n",
    "    rec_name, sorter = result_name\n",
    "    sorter_names_curation.append(sorter)\n",
    "    \n",
    "    # firing rate threshold\n",
    "    sorting_curated = st.curation.threshold_firing_rates(sorting, duration_in_frames=num_frames,\n",
    "                                                         threshold=firing_rate_threshold, \n",
    "                                                         threshold_sign='less')\n",
    "    \n",
    "    # isi violation threshold\n",
    "    sorting_curated = st.curation.threshold_isi_violations(sorting_curated, duration_in_frames=num_frames,\n",
    "                                                           threshold=isi_violation_threshold, \n",
    "                                                           threshold_sign='greater')\n",
    "    \n",
    "    # isi violation threshold\n",
    "    sorting_curated = st.curation.threshold_snrs(sorting_curated, recording=recording_processed,\n",
    "                                                 threshold=snr_threshold, \n",
    "                                                 threshold_sign='less')\n",
    "    sorting_auto_curated.append(sorting_curated)\n",
    "    print(f\"{sorter} found {len(sorting_curated.get_unit_ids())} units after auto curation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 7) Save to NWB; writes only the spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The name of the NWBFile from the Vermin output\n",
    "nwbfile_path = base_data_path / \"TowersTask.nwb\"\n",
    "\n",
    "# Choose the sorting extractor from the notebook environment you would like to write to NWB\n",
    "chosen_sorting_extractor = sorting_outputs[('rec0', 'ironclust')]\n",
    "\n",
    "se.NwbSortingExtractor.write_sorting(\n",
    "    sorting=chosen_sorting_extractor,\n",
    "    save_path=nwbfile_path,\n",
    "    overwrite=False  # this appends the file\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
