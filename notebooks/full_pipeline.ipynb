{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpikeInterface pipeline for Feldman Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "import spikeextractors as se\n",
    "import spiketoolkit as st\n",
    "import spikesorters as ss\n",
    "import spikecomparison as sc\n",
    "import spikewidgets as sw\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a) Load AP recordings, LF recordings and TTL signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_path = Path(\"D:/Feldman\")\n",
    "# #base_path = Path(\"/Users/abuccino/Documents/Data/catalyst/brody/A256_bank1_2020_09_30_g0\")\n",
    "# #base_data_path = Path(\"D:/Neuropixels/Neuropixels/A256_bank1_2020_09_30/A256_bank1_2020_09_30_g0\")\n",
    "# base_data_path = Path(\"20210115_NPX_and_behavior/2021_01_15_E105/towersTask_g0\")\n",
    "# ap_bin_path = base_data_path / \"towersTask_g0_imec0\" / \"towersTask_g0_t0.imec0.ap.bin\"\n",
    "# lf_bin_path = base_data_path / \"towersTask_g0_imec0\" / \"towersTask_g0_t0.imec0.lf.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path(\"/Users/abuccino/Documents/Data/catalyst/feldman/\")\n",
    "session_name = \"LR_210209_2_g1\"\n",
    "# session_name = \"LR_210209_g1\"\n",
    "# session_name = \"LR_210209_2_g0\"\n",
    "# session_name = \"LR_210209_2_g1\"\n",
    "ap_bin_path = base_path / session_name / f\"{session_name}_imec0\" / f\"{session_name}_t0.imec0.ap.bin\"\n",
    "lf_bin_path = base_path / session_name / f\"{session_name}_imec0\" / f\"{session_name}_t0.imec0.lf.bin\"\n",
    "nidq_bin_path = base_path / session_name / f\"{session_name}_t0.nidq.bin\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make spikeinterface folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_folder = Path('.')\n",
    "spikeinterface_folder = recording_folder / \"spikeinterface\"\n",
    "spikeinterface_folder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) stub recording for fast testing; set to False for running processing pipeline on entire data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stub_test = False\n",
    "nsec_stub = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_ap = se.SpikeGLXRecordingExtractor(ap_bin_path)\n",
    "recording_lf = se.SpikeGLXRecordingExtractor(lf_bin_path)\n",
    "\n",
    "if stub_test:\n",
    "    recording_ap = se.SubRecordingExtractor(recording_ap, end_frame=int(nsec_stub*recording_ap.get_sampling_frequency()))\n",
    "    recording_lf = se.SubRecordingExtractor(recording_lf, end_frame=int(nsec_stub*recording_lf.get_sampling_frequency()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Sampling frequency AP: {recording_ap.get_sampling_frequency()}\")\n",
    "print(f\"Sampling frequency LF: {recording_lf.get_sampling_frequency()}\")      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load TTL signals\n",
    "### ToDo: but general sketch of common methods shown below\n",
    "\n",
    "### (Option 1): Use TTLs from the ap.bin file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttl, states = recording_ap.get_ttl_events(channel_id=6)\n",
    "rising_times = ttl[states==1]\n",
    "print(f\"Number of TTL events in ap file: {len(rising_times)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(rising_times) > 0:\n",
    "    start_time = recording_ap.frame_to_time(rising_times[0])\n",
    "    start_frame_ap = int(recording_ap.time_to_frame(start_time))\n",
    "    start_frame_lf = int(recording_lf.time_to_frame(start_time))\n",
    "    print(f\"Start frame AP: {start_frame_ap}\")\n",
    "    print(f\"Start frame LF: {start_frame_lf}\")    \n",
    "else:\n",
    "    print(\"No TTL events found in ap file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Option 2): Use TTLs from the nidq.bin file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_nidq = se.SpikeGLXRecordingExtractor(nidq_bin_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_nidq.get_sampling_frequency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.plot_timeseries(recording_nidq, trange=[0, 120])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synchronize recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_ap_sync = se.SubRecordingExtractor(recording_ap, start_frame=start_frame_ap)\n",
    "recording_lf_sync = se.SubRecordingExtractor(recording_lf, start_frame=start_frame_lf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ts_ap = sw.plot_timeseries(recording_ap, channel_ids=recording_ap.get_channel_ids()[::4], trange=[0, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ts_lf = sw.plot_timeseries(recording_lf, channel_ids=recording_lf.get_channel_ids()[::10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_cmr = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if apply_cmr:\n",
    "    recording_processed = st.preprocessing.common_reference(recording_ap_sync)\n",
    "else:\n",
    "    recording_processed = recording_ap_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames = recording_processed.get_num_frames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates, amps = st.postprocessing.compute_channel_spiking_activity(\n",
    "    recording_processed,\n",
    "    n_jobs=16,\n",
    "    chunk_mb=4000,\n",
    "    start_frame=10*30000,\n",
    "    end_frame=20*30000, \n",
    "    detect_threshold=8,\n",
    "    recompute_info=True, \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2)\n",
    "sw.plot_activity_map(recording_processed, activity=\"rate\", colorbar=True, ax=axs[0])\n",
    "sw.plot_activity_map(recording_processed, activity=\"amplitude\", colorbar=True, ax=axs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Run spike sorters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorter_list = [\n",
    "    'tridesclous',\n",
    "    #'spykingcircus',\n",
    "    'herdingspikes',\n",
    "    #'kilosort2',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inspect sorter-specific parameters and defaults\n",
    "for sorter in sorter_list:\n",
    "    print(f\"{sorter} params description:\")\n",
    "    pprint(ss.get_params_description(sorter))\n",
    "    print(\"Default params:\")\n",
    "    pprint(ss.get_default_params(sorter))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user-specific parameters\n",
    "sorter_params = dict(\n",
    "    #kilosort2=dict(car=False, n_jobs_bin=12, chunk_mb=4000),\n",
    "    #ironclust=dict(filter=True),\n",
    "    tridesclous=dict(n_jobs_bin=12, chunk_mb=4000),\n",
    "    spykingcircus=dict(filter=True, num_workers=16),\n",
    "    herdingspikes=dict(filter=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_outputs = ss.run_sorters(\n",
    "    sorter_list=sorter_list, \n",
    "    recording_dict_or_list=dict(rec0=recording_processed),\n",
    "    working_folder=spikeinterface_folder / \"working1\",\n",
    "    mode=\"keep\", # change to \"keep\" to avoid repeating the spike sorting\n",
    "    sorter_params=sorter_params,\n",
    "    verbose=True,\n",
    "    run_sorter_kwargs=dict(raise_error=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result_name, sorting in sorting_outputs.items():\n",
    "    rec_name, sorter = result_name\n",
    "    print(f\"{sorter} found {len(sorting.get_unit_ids())} units\")\n",
    "    \n",
    "    # tridesclous sometimes has empty clusters\n",
    "    active_units = []\n",
    "    for u in sorting.get_unit_ids():\n",
    "        if len(sorting.get_unit_spike_train(u)) > 0:\n",
    "            active_units.append(u)\n",
    "    \n",
    "    if len(active_units) < len(sorting.get_unit_ids()):\n",
    "        sorting_outputs[result_name] = se.SubSortingExtractor(sorting, unit_ids=active_units)\n",
    "        print(f\"{sorter} found {len(active_units)} units after removing empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sorting_tdc = sorting_outputs[('rec0', 'tridesclous')]\n",
    "sw.plot_unit_templates(recording_processed, sorting_tdc, unit_ids=[11, 21], radius=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Post-processing: extract waveforms, templates, quality metrics, extracellular features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Set postprocessing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-processing params\n",
    "postprocessing_params = st.postprocessing.get_postprocessing_params()\n",
    "pprint(postprocessing_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# (optional) change parameters\n",
    "postprocessing_params['max_spikes_per_unit'] = 1000  # with None, all waveforms are extracted\n",
    "postprocessing_params['n_jobs'] = 16  # n jobs\n",
    "postprocessing_params['chunk_mb'] = 4000  # max RAM usage in Mb\n",
    "postprocessing_params['verbose'] = True  # max RAM usage in Mb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Set quality metric list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quality metrics\n",
    "qc_list = st.validation.get_quality_metrics_list()\n",
    "print(f\"Available quality metrics: {qc_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# (optional) define subset of qc\n",
    "qc_list = ['snr', 'isi_violation', 'firing_rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Set extracellular features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracellular features\n",
    "ec_list = st.postprocessing.get_template_features_list()\n",
    "print(f\"Available EC features: {ec_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# (optional) define subset of ec\n",
    "ec_list = ['peak_to_valley', 'halfwidth']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Postprocess all sorting outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for result_name, sorting in sorting_outputs.items():\n",
    "    rec_name, sorter = result_name\n",
    "    print(f\"Postprocessing recording {rec_name} sorted with {sorter}\")\n",
    "    tmp_folder = spikeinterface_folder / 'tmp' / sorter\n",
    "    tmp_folder.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # set local tmp folder\n",
    "    sorting.set_tmp_folder(tmp_folder)\n",
    "    \n",
    "    # compute waveforms\n",
    "    waveforms = st.postprocessing.get_unit_waveforms(recording_processed, sorting, **postprocessing_params)\n",
    "    \n",
    "    # compute templates\n",
    "    templates = st.postprocessing.get_unit_templates(recording_processed, sorting, **postprocessing_params)\n",
    "    \n",
    "    # comput EC features\n",
    "    ec = st.postprocessing.compute_unit_template_features(\n",
    "        recording_processed,\n",
    "        sorting,\n",
    "        feature_names=ec_list,\n",
    "        as_dataframe=True\n",
    "    )\n",
    "\n",
    "    # compute QCs\n",
    "    qc = st.validation.compute_quality_metrics(\n",
    "        sorting,\n",
    "        recording=recording_processed, \n",
    "        metric_names=qc_list,\n",
    "        as_dataframe=True\n",
    "    )\n",
    "    \n",
    "    # export to phy\n",
    "    if sorter == \"kilosort2\":\n",
    "        phy_folder = spikeinterface_folder / 'phy' / sorter\n",
    "        phy_folder.mkdir(parents=True, exist_ok=True)\n",
    "        st.postprocessing.export_to_phy(recording_processed, sorting, phy_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Run phy and load curated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!phy template-gui spikeinterface/phy/kilosort2/params.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_manual_curated = se.PhySortingExtractor(phy_folder, exclude_cluster_groups=['noise'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Kilosort2 found {len(sorting_manual_curated.get_unit_ids())} units after manual curation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 5) Ensemble spike sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if len(sorting_outputs) > 1:\n",
    "    # retrieve sortings and sorter names\n",
    "    sorting_list = []\n",
    "    sorter_names_comp = []\n",
    "    for result_name, sorting in sorting_outputs.items():\n",
    "        rec_name, sorter = result_name\n",
    "        sorting_list.append(sorting)\n",
    "        sorter_names_comp.append(sorter)\n",
    "        \n",
    "    # run multisorting comparison\n",
    "    mcmp = sc.compare_multiple_sorters(sorting_list=sorting_list, name_list=sorter_names_comp)\n",
    "    \n",
    "    # plot agreement results\n",
    "    w_agr = sw.plot_multicomp_agreement(mcmp)\n",
    "    \n",
    "    # extract ensamble sorting\n",
    "    sorting_ensemble = mcmp.get_agreement_sorting(minimum_agreement_count=2)\n",
    "    \n",
    "    print(f\"Ensamble sorting among {sorter_list} found: {len(sorting_ensemble.get_unit_ids())} units\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.plot_rasters(sorting_ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 6) Automatic curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define curators and thresholds\n",
    "isi_violation_threshold = 0.5\n",
    "snr_threshold = 5\n",
    "firing_rate_threshold = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sorting_auto_curated = []\n",
    "sorter_names_curation = []\n",
    "for result_name, sorting in sorting_outputs.items():\n",
    "    rec_name, sorter = result_name\n",
    "    sorter_names_curation.append(sorter)\n",
    "    \n",
    "    # firing rate threshold\n",
    "    sorting_curated = st.curation.threshold_firing_rates(\n",
    "        sorting,\n",
    "        duration_in_frames=num_frames,\n",
    "        threshold=firing_rate_threshold, \n",
    "        threshold_sign='less'\n",
    "    )\n",
    "    \n",
    "    # isi violation threshold\n",
    "    sorting_curated = st.curation.threshold_isi_violations(\n",
    "        sorting_curated,\n",
    "        duration_in_frames=num_frames,\n",
    "        threshold=isi_violation_threshold, \n",
    "        threshold_sign='greater'\n",
    "    )\n",
    "    \n",
    "    # isi violation threshold\n",
    "    sorting_curated = st.curation.threshold_snrs(\n",
    "        sorting_curated,\n",
    "        recording=recording_processed,\n",
    "        threshold=snr_threshold, \n",
    "        threshold_sign='less'\n",
    "    )\n",
    "    sorting_auto_curated.append(sorting_curated)\n",
    "    print(f\"{sorter} found {len(sorting_curated.get_unit_ids())} units after auto curation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 7) Save to NWB; writes only the spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The name of the NWBFile containing behavioral or full recording data\n",
    "nwbfile_path = base_data_path / f\"Feldman_{session_name}.nwb\"\n",
    "\n",
    "# Choose the sorting extractor from the notebook environment you would like to write to NWB\n",
    "chosen_sorting_extractor = sorting_outputs[('rec0', 'ironclust')]\n",
    "\n",
    "se.NwbSortingExtractor.write_sorting(\n",
    "    sorting=chosen_sorting_extractor,\n",
    "    save_path=nwbfile_path,\n",
    "    overwrite=False  # this appends the file. True would write a new file\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
